{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Super-Resolution with PyTorch\n",
    "\n",
    "In this notebook, we'll learn how to implement an image super-resolution model using PyTorch. Super-resolution is a technique that enhances the resolution of images using deep learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "We'll import the necessary libraries for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "\n",
    "We will define a simple convolutional neural network model for super-resolution based on the SRCNN (Super-Resolution Convolutional Neural Network) architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=9, padding=4)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n",
    "        \n",
    "        # Transposed convolution layer to upscale the image\n",
    "        self.deconv = nn.ConvTranspose2d(3, 1, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.deconv(x)  # Transposed convolution to upscale the image\n",
    "        return x\n",
    "\n",
    "model = SRCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "For this example, we'll use the MNIST dataset, which consists of small images. We'll preprocess the images to be of lower resolution and use them to train our super-resolution model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_lr = transforms.Compose([\n",
    "    transforms.Resize((16, 16)),  # Downsample to low resolution\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# High resolution target images\n",
    "transform_hr = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize to high resolution\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "full_dataset_hr = MNIST(root='./data', train=True, download=True, transform=transform_hr)\n",
    "\n",
    "# Create a subset of 560 images\n",
    "indices = list(range(len(full_dataset_hr)))\n",
    "np.random.shuffle(indices)\n",
    "subset_indices = indices[:560]\n",
    "hr_subset = Subset(full_dataset_hr, subset_indices)\n",
    "trainloader_hr = DataLoader(hr_subset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Loss Function and Optimizer\n",
    "\n",
    "We'll use Mean Squared Error (MSE) as our loss function and Adam optimizer to update the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Training the Model\n",
    "\n",
    "We'll train the model using the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for idx, (hr_images, _) in enumerate(trainloader_hr):\n",
    "        # Generate low-resolution images by downsampling high-resolution images\n",
    "        lr_images = torch.stack([transform_lr(transforms.ToPILImage()(img)) for img in hr_images])\n",
    "\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(lr_images)\n",
    "\n",
    "        if epoch == 0 and idx == 0:\n",
    "            print(f'LR Images Size: {lr_images.size()}')\n",
    "            print(f'HR Images Size: {hr_images.size()}')\n",
    "            print(f'Model Output Size: {outputs.size()}')\n",
    "\n",
    "        loss = criterion(outputs, hr_images)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(trainloader_hr)}')\n",
    "\n",
    "print('Training completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(lr_images, hr_images, sr_images):\n",
    "    lr_images = lr_images.permute(0, 2, 3, 1).numpy()\n",
    "    hr_images = hr_images.permute(0, 2, 3, 1).numpy()\n",
    "    sr_images = sr_images.permute(0, 2, 3, 1).numpy()\n",
    "    \n",
    "    fig, axs = plt.subplots(3, 5, figsize=(15, 9))\n",
    "    for i in range(5):\n",
    "        axs[0, i].imshow(np.clip(hr_images[i], 0, 1))\n",
    "        axs[0, i].set_title('High Resolution')\n",
    "        axs[0, i].axis('on')\n",
    "        \n",
    "        axs[1, i].imshow(np.clip(lr_images[i], 0, 1))\n",
    "        axs[1, i].set_title('Low Resolution')\n",
    "        axs[1, i].axis('on')\n",
    "        \n",
    "        axs[2, i].imshow(np.clip(sr_images[i], 0, 1))\n",
    "        axs[2, i].set_title('Super-Resolved')\n",
    "        axs[2, i].axis('on')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualization\n",
    "hr_images = next(iter(trainloader_hr))[0]\n",
    "lr_images = torch.stack([transform_lr(transforms.ToPILImage()(img)) for img in hr_images])\n",
    "with torch.no_grad():\n",
    "    sr_images = model(lr_images)\n",
    "show_images(lr_images, hr_images, sr_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arqesp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
