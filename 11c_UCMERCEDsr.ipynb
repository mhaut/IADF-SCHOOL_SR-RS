{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUSTOM CNN FOR SR OF REMOTE SENSING IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCMERCED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "We'll import the necessary libraries for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the UCMERCED Dataset\n",
    "\n",
    "To effectively work with the UCMERCED dataset, it's essential to split it into training and testing (or validation) sets. This process ensures that you can train your model on one subset and evaluate its performance on another. Follow these steps to achieve this:\n",
    "\n",
    "## Step 1: Define a Split Function\n",
    "\n",
    "First, you need to create a function that splits the dataset into training and testing subsets. This can be efficiently done using `sklearn.model_selection.train_test_split`. Here's a sample implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(indices, test_size=0.2, random_state=None, use_subset=False):\n",
    "    \"\"\"\n",
    "    Splits dataset indices into training and testing subsets.\n",
    "\n",
    "    Parameters:\n",
    "    - indices (list or array): List of dataset indices.\n",
    "    - test_size (float): Proportion of the dataset to include in the test split.\n",
    "    - random_state (int, optional): Seed for the random number generator.\n",
    "\n",
    "    Returns:\n",
    "    - train_indices (array): Indices for the training set.\n",
    "    - test_indices (array): Indices for the testing set.\n",
    "    \"\"\"\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        indices, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    if use_subset:\n",
    "        train_indices = train_indices[:100]\n",
    "        test_indices = test_indices[:100]\n",
    "    return train_indices, test_indices\n",
    "\n",
    "\n",
    "class UCMERCEDDataset(Dataset):\n",
    "    def __init__(self, image_dir, indices=None, transform=None, scale_factor=2):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - image_dir (str): Directory with images.\n",
    "        - indices (list or array, optional): Indices to select a subset of the data.\n",
    "        - transform (callable, optional): A function/transform to apply to the images.\n",
    "        - scale_factor (int, optional): Factor by which to scale down the high-resolution images.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.scale_factor = scale_factor\n",
    "        self.indices = indices\n",
    "\n",
    "        # Get all image files\n",
    "        self.image_files = []\n",
    "        for f in os.listdir(image_dir):\n",
    "            for g in os.listdir(os.path.join(image_dir,f)):\n",
    "                if g.endswith('.tif'): # change if other dataset with other extesion is used\n",
    "                    self.image_files.append(os.path.join(f,g))\n",
    "        \n",
    "        # If indices are provided, filter the image files\n",
    "        if self.indices is not None:\n",
    "            self.image_files = [self.image_files[i] for i in self.indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        hr_image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        # Apply transforms if provided\n",
    "        if self.transform:\n",
    "            hr_image = self.transform(hr_image)\n",
    "\n",
    "        # Create low-resolution image tensor by resizing\n",
    "        lr_image = F.interpolate(\n",
    "            hr_image.unsqueeze(0),\n",
    "            scale_factor=1 / self.scale_factor,\n",
    "            mode='bicubic',\n",
    "            align_corners=False\n",
    "        ).squeeze(0)  # Remove batch dimension\n",
    "\n",
    "        return lr_image, hr_image\n",
    "    \n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),              # Resize to 256x256\n",
    "    transforms.RandomCrop(224),         # Randomly crop and resize to 64x64\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.RandomVerticalFlip(),    # Optional: Random vertical flip\n",
    "    transforms.ToTensor(),              # Convert image to Tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),              # Resize to 256x256\n",
    "    transforms.CenterCrop(224),         # Randomly crop and resize to 64x64\n",
    "    transforms.ToTensor(),              # Convert image to Tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "image_dir = './UCMerced_LandUse/Images'\n",
    "dataset = UCMERCEDDataset(image_dir=image_dir)\n",
    "train_indices, test_indices = split_dataset(list(range(len(dataset))), use_subset=False)\n",
    "\n",
    "# Instantiate dataset and dataloader\n",
    "train_dataset = UCMERCEDDataset(image_dir=image_dir, indices=train_indices, transform=train_transform, scale_factor=2)\n",
    "test_dataset  = UCMERCEDDataset(image_dir=image_dir, indices=test_indices, transform=test_transform, scale_factor=2)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "print(\"Size of train set\", len(train_loader.dataset))\n",
    "print(\"Size of test set\",  len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "\n",
    "We will define a simple convolutional neural network model for super-resolution based on the SRCNN (Super-Resolution Convolutional Neural Network) architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n",
    "        \n",
    "        # Transposed convolution layer to upscale the image\n",
    "        self.deconv = nn.ConvTranspose2d(3, 3, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.deconv(x)  # Transposed convolution to upscale the image\n",
    "        return x\n",
    "\n",
    "model = SRCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Loss Function and Optimizer\n",
    "\n",
    "We'll use Mean Squared Error (MSE) as our loss function and Adam optimizer to update the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Training the Model\n",
    "\n",
    "We'll train the model using the UCMERCED dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(hr_images, lr_images, sr_images):\n",
    "   \n",
    "    fig, axs = plt.subplots(3, 5, figsize=(15, 9), gridspec_kw={'height_ratios': [1, 0.5, 1]})\n",
    "    for i in range(5):\n",
    "        axs[0, i].imshow(hr_images[i])\n",
    "        axs[0, i].set_title('High Resolution')\n",
    "        axs[0, i].axis('on')\n",
    "        \n",
    "        axs[1, i].imshow(lr_images[i])\n",
    "        axs[1, i].set_title('Low Resolution')\n",
    "        axs[1, i].axis('on')\n",
    "        \n",
    "        axs[2, i].imshow(sr_images[i])\n",
    "        axs[2, i].set_title('Super-Resolved')\n",
    "        axs[2, i].axis('on')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def denormalize(tensor, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]):\n",
    "    mean = torch.tensor(mean).view(1, 3, 1, 1)\n",
    "    std = torch.tensor(std).view(1, 3, 1, 1)\n",
    "    return torch.clip(tensor * std + mean, 0, 1)\n",
    "\n",
    "\n",
    "def draw_images(test_loader, device):\n",
    "    lr_images, hr_images = next(iter(test_loader))\n",
    "    lr_images, hr_images = lr_images.to(device), hr_images.to(device)\n",
    "    sr_images = model(lr_images)\n",
    "\n",
    "    denormalized_hr_images = denormalize(hr_images.cpu(), mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    denormalized_lr_images = denormalize(lr_images.cpu(), mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    denormalized_sr_images = denormalize(sr_images.cpu(), mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "    hr_images = [transforms.ToPILImage()(img) for img in denormalized_hr_images]\n",
    "    lr_images = [transforms.ToPILImage()(img) for img in denormalized_lr_images]\n",
    "    sr_images = [transforms.ToPILImage()(img) for img in denormalized_sr_images]\n",
    "\n",
    "    show_images(hr_images, lr_images, sr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for lr_images, hr_images in train_loader:\n",
    "        lr_images, hr_images = lr_images.to(device), hr_images.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(lr_images)\n",
    "        loss = criterion(outputs, hr_images)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * lr_images.size(0)\n",
    "\n",
    "    if epoch % 2:\n",
    "        draw_images(test_loader, device)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "print('Training completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arqesp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
